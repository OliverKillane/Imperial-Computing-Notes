\chapter{Streams}

\section{Motivation}
There are many data processing applications that deal with streams of relevance-priority data (e.g Sports data, weather data, telemetry (spacecraft, service usage)).
\begin{itemize}
    \item Recent events are valuable, old events are not (and can be discarded or sent to data warehouse after some time)
    \item Users run a static query on an unbounded stream of data
    \item The state of the system must be bounded (limited memory)
    \item Timestamps for events are important (tradeoffs between performance, and accuracy), the order at which events are received is important.
    \item Results can be approximate
\end{itemize}

\section{Push Operators}
Rather than operators pulling in tuples (as in \textit{volcano processing}), operators push tuples to the next stage.
\inputminted[firstline=10, lastline=14]{cpp}{streams/code/streams/streams.h}
\begin{itemize}
    \item As with volcano and bulk processing we can also send references to data (e.g indexes into a larger backing table) to avoid copies.
    \item Virtual method used to allow operators to be combined into queries at runtime.
    \item Can use \mintinline{cpp}{std::move} to reduce deep copying for large \mintinline{cpp}{Event} types (e.g vectors of variants).
\end{itemize}

\subsection{Naive Implementation}
\subsubsection{Output to Console}
Some form of output operator is required to send data to the user (e.g player positions sent over the network to a live sports match website).
\\
\\ Here a basic Output operator pushes to a stream (e.g a file with \mintinline{cpp}{std::ofstream}, or to the console with \mintinline{cpp}{std::cout}).
\inputminted{cpp}{streams/code/streams/operators/output.h}

\subsubsection{Selection}
\inputminted{cpp}{streams/code/streams/operators/select.h}
\subsubsection{Project}
Generalised here to just map a function over the stream.
\inputminted{cpp}{streams/code/streams/operators/project.h}

\subsubsection{Data Source}
We also need to be able to pipe data directly into a chain of operators.
\begin{itemize}
    \item Can implement a class to directly call \mintinline{cpp}{PushOperator::process}.
    \item Here a convenient interface is used to demonstrate terminal input.
\end{itemize}
\inputminted{cpp}{streams/code/streams/operators/source.h}

\subsubsection{Combining Operators}
We can then combine operators to form queries.
\begin{minted}{cpp}
// Configure output
Output<int> console(std::cout);

// Build query
Project<int, int> mult(&console, [](auto i){ return i * 3; });
Select<int> even(&mult, [](auto &i){ return i % 2 == 0; });
UserInput<int> user(&even, std::cin);

// Get input stream
user.run();
\end{minted}
\begin{minted}{bash}
1
2
->6
3
4
->12
\end{minted}

\subsection{PushBack}
Resource usage of operators is important.
\begin{itemize}
    \item Some operators may buffer rows (in order to resolve order, retain aggates about current window (e.g min/max))
    \item Operators could be extracted to different threads, in which case some operators may run slowly compared with other operators.
\end{itemize}
One way to inform upstream operators about \textit{backpressure} from pressured operators downstream is by returning some measure of pressure.
\begin{minted}{cpp}
template<typename Event>
class PushOperator {
public:
    // return pressure on operator
    virtual float process(Event data) = 0;
};
\end{minted}
Operators can then use some heuristic of time taken, buffer sizes and the \textit{backpressure} from operators it pushes to.

\section{Time}
Systems often implicitly provide timestamps for pushed data, for example when joining data based on timestamps.
\begin{itemize}
    \item Needs to be consistent (same stream results in the same output data).
    \item Needs to be performant/low overhead (reduce backpressure).
\end{itemize}

\begin{definitionbox}{Processing-Time}
    Each operator timestamps data when it is pushed to the operator.
    \begin{minted}{cpp}
class SomeOperator : public Operator {
    // ... internal state
public:
    void process(InputEvent data) override {
        auto data_timestamp = std::chrono::system_clock::now();
        // ... use data & data_timestamp
    }
};
    \end{minted}
    \begin{center}
        \begin{tabular}{c | c | c}
            \textcolor{red}{inconsistent} & \textcolor{red}{unpredicatable} & \textcolor{ForestGreen}{low-overhead} \\
        \end{tabular}
    \end{center}
\end{definitionbox}

\begin{definitionbox}{Ingestion-Time}
    Timestamp when received by the system (i.e the source object that pushes to the first operator).
    \begin{minted}{cpp}
class NetworkSource : public Source {
    // ... internal state
public:
    void run() override {
        for (;;) if (!network.buffer_empty()) {
            auto data_timestamp = std::chrono::system_clock::now();
            auto data = network.pop_next();
            // ... use data & data_timestamp
        }
    }
};
    \end{minted}
    \begin{center}
        \begin{tabular}{c | c | c}
            \textcolor{ForestGreen}{consistent} & \textcolor{red}{unpredicatable} & \textcolor{orange}{medium-overhead} \\
        \end{tabular}
    \end{center}
\end{definitionbox}
\begin{definitionbox}{Event-Time}
    Timestamps externally provided by the source supplying events to the data processing system as part of data input.
    \begin{itemize}
        \item System needs to ensure timestamps are ordered (external provider may not be correct).
    \end{itemize}
    \begin{minted}{cpp}
class NetworkSource : public Source {
    // ... internal state
public:
    void run() override {
        for (;;) if (!network.buffer_empty()) {
            auto data = network.pop_next();
            // can just treat timestamp as normal data, or extract specially
            auto data_timestamp = data.timestamp;
            // ... use data & data_timestamp
        }
    }
};
    \end{minted}
    \begin{center}
        \begin{tabular}{c | c | c}
            \textcolor{ForestGreen}{consistent} & \textcolor{ForestGreen}{predicatable} & \textcolor{red}{high-overhead} \\
        \end{tabular}
    \end{center}
\end{definitionbox}

\subsection{In-Order Processing}
\begin{definitionbox}{In-Order Processing}
    Events are assumed to be entered in timestamp order (or by some other monotonically progressing attribute - e.g counter).
    \begin{itemize}
        \item Greatly simplifies stream system implementation, a powerful guarantee.
        \item Difficult to ensure order guarantee holds (on a distributed, asynchronous system there is not global clock)
    \end{itemize}
\end{definitionbox}
While it is usually prohibitively difficult to implement In-Order processing, we still need to have some guarantees on ordering for queries that rely on in-order data.
\begin{itemize}
    \item If a single server is used to apply timestamps it can become a bottleneck.
    \item We can make some assumptions on bounds of how out-of-order messages can be received.
    \item We can reduce the \textit{In-Order} to a \textit{Sort-Order}.
\end{itemize}

\subsubsection{Transactions}
The stream of events is treated as a sequence of transactions.
\begin{itemize}
    \item All events are inserted into persistent database
\end{itemize}
\begin{minted}{sql}
-- Store all inputs to persistent backing table
ON IncomingEvent newEvent INSERT INTO event_backing_table VALUES (newEvent)

-- Stream out data (e.g by selecting based on a predicate)
SELECT * FROM event_backing_table WHERE some_predicate(x, y, newEvent);
\end{minted}
\begin{tabbox}{consbox}
    \textbf{Finite Memory} & Streams are infinite, persistent database must have older entries cleared/garbage collected. \\
\end{tabbox}

\subsubsection{Lateness Bounds}
A lateness bound is assumed for any event, events outside this bound are dropped.
\begin{minted}{sql}
ON IncomingEvent newEvent INSERT INTO event_backing_table VALUES (newEvent)
SELECT * FROM event_backing_table WHERE some_predicate(x, y, newEvent)

-- Delete old data from the table using the new event's timestamp
DELETE FROM event_a_backing_table WHERE timestamp < (newEvent.timestamp - LATENESS_BOUND);
\end{minted}
\begin{tabbox}[.7\textwidth]{consbox}
    \textbf{Tune Lateness Bound} & If the bound is too small (many tuples dropped), too large and memory resource becomes pressured by large backing table \\
\end{tabbox}

\subsubsection{Watermarks/Punctuation}
The user sends a specific \textit{punctuation} event to inform the system that all older events than a specific timestamp can be dropped.
\begin{minted}{sql}
ON IncomingEventWatermark e DELETE FROM event_backing_table WHERE timestamp < e.up_to_time;
\end{minted}
\begin{tabbox}[.7\textwidth]{prosbox}
    \textbf{User Configurable} & The user can specify when events should be dropped. \\
\end{tabbox}

\subsection{Windows}
\begin{center}
    \includegraphics[width=.9\textwidth]{streams/images/window_types.drawio.png}
\end{center}
There are also \textit{Session Windows} open and closed by an event (e.g user loggin in \& out).
\\
\\ \textit{Lateness bounds} are an implementation detail for ordering streams
\\
\\ \textit{Windows} are SQL supported abstractions for viewing a slice of a stream, and are part of the language semantics.
\begin{sidenotebox}{SQL Windows}
    Despite being originally designed only for persistent databases, SQL added window functions in SQL 2003 (\href{https://en.wikipedia.org/wiki/SQL:2003}{see changelog}).
\end{sidenotebox}
\begin{minted}{sql}
SELECT avg(temp) OVER (
    ORDER BY timestamp
    ROWS BETWEEN 5 PRECEDING AND 5 FOLLOWING
) AS smoothed_temp
FROM SpaceStationTemp;
\end{minted}
We can run aggregate functions on a window:
\begin{minted}{sql}
min, max, sum, count -- Distributive
avg                  -- Algebraic
percentile_cont      -- Holistic
\end{minted}
Percentiles require the entire window to be read (cannot subdivide the window and combine as with \mintinline{sql}{sum}, \mintinline{sql}{count}).
\begin{definitionbox}{Invertible Function}
    \begin{center}
        \includegraphics[width=.7\textwidth]{streams/images/invertible_agreggate.drawio.png}
    \end{center}
    Functions with an inverse that can be used to remove rows sliding out of the window from the aggregation.
    \begin{minted}{sql}
sum, count, avg       -- invertible
min, max, percentiles -- non-invertible
    \end{minted}
\end{definitionbox}

\subsection{Aggregate Implementations}
We can implement basic aggregate functions using the previous \mintinline{cpp}{PushOperator<Event>} abstraction.
\subsubsection{Window Sum}
\inputminted{cpp}{streams/code/streams/operators/window_sum.h}

\subsubsection{Window Median}
\begin{sidenotebox}{Improve Me!}
    The provided algorithm must copy the entire window for every \mintinline{cpp}{WindowMedianAggregator::process}. For large window sizes this is very slow, this can be made much more efficient!
\end{sidenotebox}
\inputminted{cpp}{streams/code/streams/operators/window_median.h}


\subsection{Two Stacks Algorithm}
\begin{center}
    \includegraphics[width=.9\textwidth]{streams/images/two_stacks.drawio.png}
\end{center}
Two stacks of max size $window \ size$ are kept.
\begin{itemize}
    \item Each contains aggregates calculated from below adjacent aggregates and current value.
    \item When the front stack is full, and back stack empty (occurs every $\cfrac{1}{window \ size}$) flip the front stack, recalculate aggregates and set to back stack.
\end{itemize}
We can implement this using the previous \mintinline{cpp}{PushOperator<Event>} abstraction.
\inputminted{cpp}{streams/code/streams/operators/window_two_stack.h}
For example:
\begin{minted}{cpp}
Output<int> console(std::cout);
WindowTwoStackAggregator<int, intmax> maxints(&console, 3);
UserInput<int> user(&maxints, std::cin);
user.run();
\end{minted}
\begin{sidenotebox}{Space Efficiency}
    It is possible to implement the two-stacks algorithm more efficiently using a single vector (index from top down is back stack, bottom up is front stack).
\end{sidenotebox}

\section{Stream Joins}
\subsection{Handshake Join}
\begin{definitionbox}{Handshake Join}
    \begin{center}
        \includegraphics[width=\textwidth]{streams/images/handshake_join.drawio.png}
    \end{center}
    \begin{itemize}
        \item A \textit{nested loop join} joining over a window.
        \item Can be optimised for parallel window joins.
        \item Only works for window queries.
    \end{itemize}
\end{definitionbox}

\subsection{Symmetric Hash-Joins}
\begin{definitionbox}{Symmetric Hash-Joins}
    \begin{center}
        \includegraphics[width=.7\textwidth]{streams/images/symmetric_hash_join.drawio.png}
    \end{center}
    Both input streams build their own hashtable, while probing the other. Matches from probes are inserted into the joined output stream.
    \begin{itemize}
        \item A \textit{pipelineable} hash join
        \item Does not have a equivalent window oriented version
        \item Hashtables grow with unbounded input streams, so needs some form of garbage collection of older / not joinable hashtable entries.
    \end{itemize}
\end{definitionbox}

\subsection{Bloom Filters}
\begin{definitionbox}{Bloom Filter}
    \begin{center}
        \includegraphics[width=\textwidth]{streams/images/bloom_filter.drawio.png}
    \end{center}
    A table of bits, indexed by hashing the key used for the join. By using multiple independent hashes, the probability all collide is low.
    \begin{itemize}
        \item Collisions/false-positives still possible.
        \item Can use as many independent hashes as needed.
        \item Uses finite space.
        \item Can be used to implement a form of symmetric hash-join.
    \end{itemize}
\end{definitionbox}
\subsubsection{Tuning Bloom Filters}
\noindent Bloom filters have several parameters that can be tuned.
\\ \begin{tabular}{l p{.7\textwidth}}
    $m$        & bits in filter                       \\
    $n$        & expected number of distinct elements \\
    $k$        & number of hash functions             \\
    $\epsilon$ & False-positive rate                  \\
\end{tabular}
\[\begin{matrix}
        m \cong -1.44 \times n \times \log_2(\epsilon) & \  &
        k \cong \cfrac{m}{n} \times \log_e(2)          & \  &
        \epsilon  = \left( 1 - e^{-\cfrac{k \times n}{m}}\right)^k \\
    \end{matrix}\]
