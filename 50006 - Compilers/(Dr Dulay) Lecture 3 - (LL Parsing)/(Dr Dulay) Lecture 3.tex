\documentclass{report}
    \title{50006 - Compilers - (Dr Dulay) Lecture 3}
    \author{Oliver Killane}
    \date{09/04/22}
\input{../50006 common.tex}
\begin{document}
\maketitle
\lectlink{https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=d48e84dc-b958-462c-a0ab-ae0b016d35ff}

\section*{LL Parsing}
Top-down parsing using either recursive descent (can be hand-coded) or an \keyword{LL(1)} pushdown automaton (generated by an \keyword{LL(1)} parser-generator (e.g ANTLR)).
\termdef{LL(k) Grammar}{
	A grammar is \keyword{LL(k)} if a $k$-token lookahead is sufficient to determine which alternative of a rule to use when parsing.
	\compitem{
		\item \keyword{LL(1)} uses the current token only.
		\item \keyword{LL(0)} does not exist (would be deciding based on $0$ tokens).
		\item When using \keyword{LL/Top Down Parsing} leaf nodes are constructed from the root.
	}
	The parser created for the grammar can be implemented as either a \keyword{DFA} or to parse by \keyword{recursive descent}.
	\centerimage{width=0.9\textwidth}{creating ll parser}
}

\termdef{LL(1) Grammar}{
	A grammar is \keyword{LL(1)} if for a rule $A \to \alpha \ | \ \beta$ ($A$ is non-terminal).
	\[\begin{split}
			& first(\alpha) \cap first(\beta) = \emptyset \\
			\land & \epsilon \in first(\alpha) \Rightarrow (first(\beta) \cap follow(A) = \emptyset) \\
			\land & \epsilon \in first(\beta) \Rightarrow (first(\alpha) \cap follow(A) = \emptyset) \\
		\end{split}\]
	\centerimage{width=0.9\textwidth}{ll(1) grammar}
	This extends to more than two alternatives.
}

\termdef{Extended Backus-Naur Form (BNF)}{
	Used for writing context free grammars, and includes several useful features:
	\begin{center}
		\begin{tabular}{l l}
			$\{\alpha\}$ & 0 or more occurrences of $\alpha$  \\
			$[\alpha]$   & $0$ or $1$ occurrences of $\alpha$ \\
			$(\dots)$    & A way to group elements together   \\
		\end{tabular}
	\end{center}
	For example we can left factor rules with alternatives that have intersecting first sets.
	\[\begin{split}
			Expr &\to Term \ \text{'+'} \ Expr \ | \ Term \\
			& \text{  then becomes  } \\
			Expr &\to Term \ [\text{'+'} \ Expr] \\
		\end{split}\]
	Or we can remove left recursion:
	\[\begin{split}
			Sequence & \to Sequence \ \text{';'} \ Statement \ | \ Statement \\
			& \text{  then becomes  } \\
			Sequence & \to Statement \ \{\text{';'} \ Statement\}\\
		\end{split}\]
}

\termdef{Recursive Descent Parser}{
	Consists of a set of parse functions for each rule which take in some tokens, and return remaining tokens and a generated \keyword{AST}.
	\\
	\\ We can use a basic function for matching \keyword{terminal} tokens:
	\begin{center}
		\begin{minipage}{0.9\textwidth}
			\codelist{Python}{match token.py}
		\end{minipage}
	\end{center}
	We can apply some basic rules for the main patterns:
	\begin{center}
		\begin{minipage}{0.9\textwidth}
			\codelist{Python}{rule patterns.py}
		\end{minipage}
	\end{center}
}
\example{Statements}{
	\[\begin{split}
			Stat &\to IfStat \ | \ BeginStat \ | \ PrintStat \\
			IfStat &\to \text{'if'} \ Expr \ \text{'then'} \ Stat \ [\text{'else'} \ Stat] \ \text{'fi'} \\
			BeginSTat &\to \text{'begin'} \ Stat \ \{\text{';'} \ Stat\} \ \text{'end'} \\
			PrintStat &\to \text{'print'} \ Expr \\
		\end{split}\]
	\begin{center}
		\begin{minipage}{0.9\textwidth}
			\codelist{Python}{rules example.py}
		\end{minipage}
	\end{center}
}

\subsection*{AST Construction}
Class hierarchies can be used to create organise nodes into variants of a given type (e.g if statements, print statements and assignments are all statements, so implement/inherit from some STatement class/interface).
\sidenote{Other languages}{
	While in languages such as Java or Python, class hierarchies are used to implement ASTs other languages have cleaner representations.
	\compitem{
		\item In \keyword{Haskell} the data keyword can be used to build an \keyword{ADT} for an \keyword{AST}
		\item Rust supports enums similar to the haskell data keyword.
	}
}

\subsection*{CFG $\to$ LL(1) Conversion}
Transformations must be applied to a non-LL(1) context free grammar, which cannot always be automated.
\compitem{
	\item Left Recursion Removal and Substitution are usually applied first.
	\item The semantics of the grammar must be maintained.
	\item Readability is a key consideration, expecially if the language is to be extended in future.
}

\termdef{Left Factorisation}{
	Where two or more alternatives of a rule have a common prefix (first element to be parsed), factor this to be parsed before determining which alternative to parse.
	\begin{center}
		\begin{tabular}{l l l}
			\textbf{non-LL(1)}      & \textbf{EBNF LL(1)}     & \textbf{BNF LL(1)}           \\
			\hline
			$A \to B \ C \ | B \ D$ & $A \to B \ (C \ | \ D)$ & $\begin{matrix*}[l]
					A &\to B \ X \\
					X &\to C \ | \ D \\
				\end{matrix*}$  \\
			\hline
			$A \to B \ C \ | B $    & $A \to B \ [C]$         & $\begin{matrix*}[l]
					A &\to B \ X \\
					X &\to C \ | \ \epsilon \\
				\end{matrix*}$ \\
		\end{tabular}
	\end{center}
}
\termdef{Substitution}{
Substituting a rule/non-terminal with its alternatives.
\compitem{
	\item Can be used to find indirect conflicts that may require left-factoring.
	\item Can produce grammars ecoding more information in a rule (makes it easier to produce the required AST)
}
\[\begin{split}
		A &\to B \ | \ C \\
		B &\to \text{'hello'} \\
		C &\to \text{'hello'} \ \text{'there'} \\
	\end{split}\]
Here we have an indirect conflict as both alternatives for $C$ start with 'hello'.
\[A \to \text{'hello'} \ | \ \text{'hello'} \ \text{'there'} \]
Now we can left-factor.
\[A \to \text{'hello'} \ [\text{'there'}] \]
}
\termdef{Left Recursion Removal}{
	Grammars cannot be \keyword{LL(1)} with left-recursion. We can use \keyword{direct left recursion removal} to eliminate left recursion from rules while leaving the grammar mostly intact.
	\[A \to X \ | \ A \ Y \Rightarrow A \to X \{Y\}\]
	For example with left-associative arithmetic expressions:
	\[\begin{split}
			Expr &\to Expr \ (\text{'+'} \ | \ \text{'-'}) \ Term \ | \ Term \\
			Term &\to Term \ (\text{'*'} \ | \ \text{'/'}) \ | \ Factor \\
			Factor &\to \text{'('} \ Expr \ \text{')'} \ | \ \underline{int} \\
		\end{split}\]
	The \keyword{parse tree} may no longer represent the associativity, hence we will need to ensure the arithmetic is still associative when we construct the \keyword{AST}:
	\[\begin{split}
			Expr &\to Term \ \{(\text{'+'} \ | \ \text{'-'}) \ Term\} \\
			Term &\to Factor \ \{(\text{'*'} \ | \ \text{'/'}) \ Factor\} \\
			Factor &\to \text{'('} \ Expr \ \text{')'} \ | \ \underline{int} \\
		\end{split}\]
}

\section*{Error Recovery}
When detecting an error in parsing\dots
\compitem{
	\item Useful error messages need to contain information collected during parsing.
	\item Error recovery can be used to allow further parse errors to be detected, with as little code as possible being skipped but avoiding nonsense/spurious error messages being created as a result.
	\item Error correction can be attempted to allow for semantic checks to be performed. The corrections must attempt to emulate what the semantics of the erroneous code likely was.
}

\termdef{Panic Mode Recovery}{
	Each parse function has a \keyword{syncset} of tokens. When an error occur, the parser skips forwards until it encounters one of these tokens.
	\compitem{
		\item Additional tokens can be provided as arguments to the parsing function (e.g add \keyword{follow set} of outer non-terminal to inner parse)
		\item The \keyword{follow set} of a rule is often used as the \keyword{syncset}
		\item
	}
	\begin{center}
		\begin{minipage}{0.9\textwidth}
			\codelist{Python}{resync.py}
		\end{minipage}
	\end{center}
}

\end{document}
